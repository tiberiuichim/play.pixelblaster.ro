<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Numpy on The Plone Expanse</title>
    <link>/tags/numpy/index.xml</link>
    <description>Recent content in Numpy on The Plone Expanse</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>@2016 Tiberiu Ichim</copyright>
    <atom:link href="/tags/numpy/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Another way to index category labels in categorization tasks</title>
      <link>/blog/2017/01/21/another-way-to-index-category-labels-in-categorization-tasks/</link>
      <pubDate>Sat, 21 Jan 2017 00:19:31 +0100</pubDate>
      
      <guid>/blog/2017/01/21/another-way-to-index-category-labels-in-categorization-tasks/</guid>
      <description>&lt;p&gt;One common task in machine-based categorization tasks is to relabel data with
a numeric value, an index, where before that data was labeled with a string.&lt;/p&gt;

&lt;p&gt;The basic Python code would be something like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;label_index = {}
labels = []
for l in string_labels:
    if l not in label_index:
        label_index[l] = len(label_index)
    labels.append(label_index[l])&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;While writing that bit of code from above, I realized that a word tokenizer can
do the same thing. This would be the equivalent, using
&lt;code&gt;keras.preprocessing.text.Tokenizer&lt;/code&gt; and numpy.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;t = Tokenizer()
t.fit_on_texts(_labels)
seqs = t.texts_to_sequences(_labels)
# seqs is a list of lists, something like:
# [[1], [2], [1], [3] ... ]
labels = np.array(seqs)[:,0] - 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And now &lt;code&gt;t.word_index&lt;/code&gt; holds the word to index mapping. &lt;code&gt;np.array(seqs)[:,0]&lt;/code&gt;
returns a list with the first element (at index 0) of the second dimension of
the np array. The arithmetic operation of the end applies to each member of
the array and is needed because the tokenizer starts indexing words at 1.&lt;/p&gt;

&lt;p&gt;Of course, the second way is convoluted, needs to process the list of labels
twice, uses two addon libraries (but probably already present for the domain
of this task) and needs some basic knowledge of numpy to be readable by others.
YMMV. I wonder which method is faster, on a bigger chunk of data.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to shuffle two arrays to the same order</title>
      <link>/blog/2017/01/20/how-to-shuffle-two-arrays-to-the-same-order/</link>
      <pubDate>Fri, 20 Jan 2017 17:24:40 +0100</pubDate>
      
      <guid>/blog/2017/01/20/how-to-shuffle-two-arrays-to-the-same-order/</guid>
      <description>&lt;p&gt;This is a small recipe on how to get two arrays with the same shape (same
length) shuffled with the same &amp;ldquo;random seed&amp;rdquo;. This is useful when the two
arrays hold related data (for example, one holds values and the other one holds
labels for those values).&lt;/p&gt;

&lt;p&gt;It takes advantage of the fact that numpy arrays can be indexed with other
arrays, something that seems really magical when compared to regular python
arrays.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; import numpy as np
&amp;gt;&amp;gt;&amp;gt; x = np.arange(10)
&amp;gt;&amp;gt;&amp;gt; y = np.arange(9, -1, -1)
&amp;gt;&amp;gt;&amp;gt; x
array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
&amp;gt;&amp;gt;&amp;gt; y
array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])
&amp;gt;&amp;gt;&amp;gt; s = np.arange(x.shape[0])
&amp;gt;&amp;gt;&amp;gt; np.random.shuffle(s)
&amp;gt;&amp;gt;&amp;gt; s
array([9, 3, 5, 2, 6, 0, 8, 1, 4, 7])
&amp;gt;&amp;gt;&amp;gt; x[s]
array([9, 3, 5, 2, 6, 0, 8, 1, 4, 7])
&amp;gt;&amp;gt;&amp;gt; y[s]
array([0, 6, 4, 7, 3, 9, 1, 8, 5, 2])
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>